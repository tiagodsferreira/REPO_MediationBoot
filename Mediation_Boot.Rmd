---
title: "Estatística Computacional - Utilização do Bootstrap para Teste Hipóteses sobre Efeitos Indiretos"
author: "Ana Machado, Ana Paquete, & Tiago Ferreira"
date: "14 de Janeiro de 2022"
output:
  html_document:
    code_folding: hide
    toc: true
    toc_float: true
urlcolor: blue
---
```{r, setup, include=FALSE}
library(jtools)
library(tidyverse)  
library(psych)
library(Hmisc)
library(ggplot2)
library(knitr)
library(kableExtra)
library(summarytools)
library(DiagrammeR)
library(GGally)
library(gridExtra)
library(simglm)

# Some customization.  You can alter or delete as desired (if you know what you are doing).
knitr::opts_chunk$set(
  tidy=FALSE,     # display code as typed
  size="small")   # slightly smaller font for code
```  

*** 
“Declaro que o presente relatório é de minha autoria e não foi utilizado previamente noutro curso ou unidade curricular, desta ou de outra instituição. As referências a outros autores (afirmações, ideias, pensamentos) respeitam escrupulosamente as regras da atribuição, e encontram-se devidamente indicadas no texto e nas referências bibliográficas, de acordo com as normas de referenciação. Tenho consciência de que a prática de plágio e auto-plágio constitui um ilícito académico”.

Ana Machado  
Ana Paquete   
Tiago Ferreira  

***
# Objetivos

# Parte 1: Introdução à mediação e efeitos indiretos

ANA & ANA

Introdução à mediação
Exemplos de aplicação
Alguns exemplos de trabalhos que utilizam a análise de mediação
https://www.sciencedirect.com/science/article/pii/S231472101500002X
https://www.thelancet.com/pdfs/journals/lanplh/PIIS2542-5196(21)00235-7.pdf
https://www.thelancet.com/pdfs/journals/lanpub/PIIS2468-2667(20)30292-9.pdf
https://www.thelancet.com/pdfs/journals/eclinm/PIIS2589-5370(21)00483-1.pdf
https://eng.uber.com/mediation-modeling/



```{r, fig.cap="Figura 1: Diagrama de modelo de mediação", echo=FALSE}
grViz("
digraph SEM {

graph [layout = neato,
       overlap = true,
       outputorder = edgesfirst]

node [shape = rectangle]

x [pos = '-3,0!', label = 'x']
m [pos = '0,2!', label = 'm']
y [pos = '3,0!', label = 'y']
em [pos = '1,2.5!', label = 'em', shape = circle]
ey [pos = '4,0.5!', label = 'ey', shape = circle]

x->m [label = 'a']
x->y [label = 'cp(c)']
m->y [label = 'b']

em->m
ey->y
}
")

```

***

# Parte 2: Simulação dos dados

Um modelo de mediação pressupõe duas variáveis preditoras (*x* e *m*) e duas variáveis dependentes (*m* e *y*). A estimação deste modelo pode ser feita através do método dos mínimos quadrados em duas etapas. Na primeira etapa regredimos o mediador (*m*) na variável preditora (*x*) para obter o parâmetro $a_{xm}$. na segunda etapa regredimos a variável dependente (*y*) em *x* e *m* para obtermos os parâmetros cp e $b_{my|x}$, respetivamente. O produto de $a_{xm}$ e $b_{my|x}$ é depois calculado, verificando-se se é significativamente diferente de zero.

Assim os parametros $a_{xm}$ e $c_{xy}$ são coeficientes brutos, enquanto que os coeficientes $b_{my|x}$ e $cp_{xy|m}$ são coeficientes ajustados. O parâmetro $a_{xm}$ representa a correlação entre as variáveis *x* e *m* enquanto o parâmetro $c_{xy}$ representa a correlação entre *x* e *y*, também denominado de efeito total. O efeito direto de *x* sobre *y* é dado pelo parâmetro $cp_{xy|m}$, correspondente á correlação parcial entre *x* e *y* da *m*. $b_{my|x}$, habitualmente não nulo numa mediação, representa o efeito de *m* sobre *y*, quando controlando o efeito de *x*. Finalmente temos o efeito indireto de *x* sobre *y* (ab) dado pelo produto dos coeficientes $a_{xm}$ e $b_{my|x}$.

Assim, temos que:  
\begin{equation}
\tag{1}
c_{xy} = cp_{xy|m} + (a_{xm} * b_{my|x})
\end{equation}

de onde:
\begin{equation}
\tag{2}
cp_{xy|m}  = c_{xy} - (a_{xm} * b_{my|x})
\end{equation}
e 
\begin{equation}
\tag{3}
(a_{xm} * b_{my|x})  = c_{xy} - cp_{xy|m}
\end{equation}

Para simular um modelo de mediação é necessário portanto definir 3 parâmetros á priori, nomeadamente  $a_{xm}$ e $b_{my|x}$ e $c_{xy}$ ou $cp_{xy|m}$. Para desenvolver a simulação dos nosso dados utilizamos valores estandardizados dos parâmetros de regressão. Neste contexto, os parâmetros poderiam variar entre -1 e 1. Assume-se assim que os seguintes parâmetros são conhecidos.   
$a_{xm} = 0.6$  
$b_{my|x} = 0.4$  
$c_{xy} = 0.3$  

Sabemos pela regra multiplicativa dos parâmetros que $ab = 0.6 * 0.4 = 0.24$ e sabemos igualmente que $cp_{xy|m} = 0.3 - 0.24 = 0.06$. Começamos por gerar dados para *x* assumindo que esta variável segue uma distribuição normal com média 0 e variância 1, $x \sim\ N(0, 1)$. No R geramos *x* com a função **rnorm**. O tamanho de amostra foi fixado a 100 ($n=100$).
```{r, warning=FALSE}
n  <-  100
a <-  .6
b <-  .4
c <-  .3
ab <-  a*b # regra multiplicativa a*b = c-cp
cp <-  c-ab
set.seed(123)
x <- rnorm(n)
ggplot(data.frame(x=x), aes(x=x)) + geom_histogram() + labs(title="histograma de x")
summary(x)
```

Tendo *x* podemos agora estimar os valores de *m* através do seguinte modelo de regressão simples:  
\begin{equation}
\tag{4}
m = a_{xm}x + \varepsilon_m
\end{equation} 

$\varepsilon_m$, a variância residual ou erro do modelo, segue uma distribuição normal com média 0 e variância constante $\sigma^2$, $\varepsilon_m \sim\ N(0, \sigma^2)$. Para mantermos a variância total em 1 calculou-se $\sigma^2$ através da seguinte fórmula:

\begin{equation}
\tag{5}
\sigma^2_m = \sqrt{1-a^2_{xm}}
\end{equation}

Usamos o quadrado do peso de regressão estandardizado para obter a variância explicada pelo modelo e subtraímos esse valor a 1 para obter a variância não explicada ou erro do modelo. A raiz quadrada é empregue para manter a estandardização da variância. No R, a computação de *m* é feita através do seguinte código.
```{r, warning=FALSE}
em <- sqrt(1-a^2)

m = a*x + em*rnorm(n) # Variância aleatória com média 0 e SD 1
ggplot(data.frame(m=m), aes(x=m)) + geom_histogram() + labs(title="histograma de m")
```

Calculam-se os valores de *y* pelo seguinte modelo de regressão:

\begin{equation}
\tag{6}
y = cp_{xy|m} + b_{my|x} + \sqrt{\varepsilon_y}
\end{equation}

Para calcular a variância do erro, sabendo que $var(x + m) =var(x) + var(m) + 2cov(xm)$, e para manter $y \sim\ N(0, 1)$, empregamos seguinte fórmula:

\begin{equation}
\tag{7}
\sigma^2_y = 1 - (cp^2_{xy|m}+b^2_{my|x}+2a_{xm}cp_{xy|m}b_{my|x})
\end{equation}  

Uma boa intuição para o parâmetro $\sigma^2_y$ é dada pelas regras de pistas propostas por Wright ([*Wright's tracing rule*](https://en.wikipedia.org/wiki/Path_analysis_(statistics)#Path_tracing_rules)). Sabendo isto, o processo de gerar dados para *y* torna-se relativamente direto. 

```{r, warning=FALSE}
# Y follows a normal distribution, Y ∼ N (0; 1)
ey = 1-(cp^2 + b^2 + 2*a*cp*b) 
y = cp*x + b*m + ey*rnorm(n)

ggplot(data.frame(y=y), aes(x=y)) + geom_histogram() + labs(title="histograma de y")
```

Os dados criados parecem consistentes com os valores dos parâmetros das distribuições pretendidos.
```{r, fig.cap="Tabela 1: Estatística descritiva - Variáveis categoriais", echo=FALSE}
df1 <-  data.frame(x,m,y)
print(dfSummary(df1, 
                varnumbers   = FALSE, 
                valid.col    = FALSE, 
                graph.magnif = 0.76),
      method = 'render', 
      na.col=FALSE,
      footnote=NA,
      headings=FALSE)
```

Da mesma forma, o padrão de correlações mostram-se consistentes com os parâmetros de regressão definidos inicialmente
```{r}
ggpairs(df1) 
```

Recorremos a uma simulação Monte Carlo para confirmar que o processo de geração de dados adotado está correto. O nosso objetivo com o processo seguinte era de perceber se com um número razoável de simulações (para fins académicos usamos n=500, embora na prática este número deverá ser bastante mais elevado) a estimação dos parâmetros de regressão convergiam para os valores de estimativa verdadeiro, isto é:  
$a_{xm} = 0.6$  
$b_{my|x} = 0.4$  
$c_{xy} = 0.3$  
Para tornar mais eficiente o processo de simulação recorremos ao pacote **[simglm](https://cran.r-project.org/web/packages/simglm/index.html)**. Este pacote segue os passos apresentados anteriormente no entanto permite simular dados de uma forma mais flexível e computacionalmente eficaz. Começamos por gerar valores para *x* assumindo que $x \sim\ N(0, 1)$.

```{r}
n  <-  200
a <-  .6
b <-  .4
c <-  .3
ab <-  a*b # regra multiplicativa a*b = c-cp
cp <-  c-ab #cp = c'

library(simglm)
sim_arguments <- list(
  formula = y ~ 1 + x,
  fixed = list(x = list(var_type = 'continuous', 
                         mean = 0, sd = 1)),
  sample_size = 200
)

dfsim_x <- simulate_fixed(data = NULL, sim_arguments)
```

```{r}
ggplot(dfsim_x, aes(x=x)) + geom_histogram() + labs(title="histograma de x")
```

Com base nos valores de *x* gerados aleatoriamente, computamos *m* recorrendo às equações 4 e 5.
```{r}
# simulação da var(em)
sim_arguments <- list(
  error = list(variance = sqrt(1-a^2)),
  sample_size = 200
)

dfsim_em <- simulate_error(data = NULL, sim_arguments)
```

```{r}
# simulação de m
sim_arguments <- list(
  formula = m ~ 1 + x,
  fixed = list(x = list(var_type = 'continuous', mean = 0, sd = 1)),
  error = list(variance = sqrt(1-a^2)),
  sample_size = 200,
  reg_weights = c(0,a)
)

simulate_fixed(data = NULL, sim_arguments) %>%
  simulate_error(sim_arguments) %>%
  generate_response(sim_arguments) %>% 
  model_fit(sim_arguments) %>%
  extract_coefficients()
```

```{r}
data_m <- simulate_fixed(data = NULL, sim_arguments) %>%
  simulate_error(sim_arguments) %>%
  generate_response(sim_arguments) 

head(data_m)
```

Finalmente, usando as equações 6 e 7, simulamos valores de *y*.
```{r}
sim_arguments <- list(
  formula =  y ~ 1 + x + m,
  error = list(variance = 1-(cp^2 + b^2 + 2*a*cp*b)),
  sample_size = 200,
  reg_weights = c(cp, b)
)

simulate_error(data = data_m[,c(2,7)], sim_arguments) %>%
  generate_response(sim_arguments) %>% 
  model_fit(sim_arguments) %>%
  extract_coefficients()

df2 <- simulate_error(data = data_m[,c(2,7)], sim_arguments) %>%
  generate_response(sim_arguments)
```

Com esperado, verificamos, para uma amostra simulada, que os resultados obtidos com o pacote *simglm* são equivalentes ao obtidos anteriormente, usando usando funções base do R. 
```{r, fig.cap="Tabela 1: Estatística descritiva - Variáveis categoriais", echo=FALSE}
print(dfSummary(df2[, c("x", "m", "y")], 
                varnumbers   = FALSE, 
                valid.col    = FALSE, 
                graph.magnif = 0.76),
      method = 'render', 
      na.col=FALSE,
      footnote=NA,
      headings=FALSE)
```

```{r}
ggpairs(df2[, c("x", "m", "y")]) 
```

Procedemos, realizando um estudo de Monte Carlo para verificar em que medida os parâmetros estimados pelos modelos de regressão definidos convergem para os parâmetros verdadeiros com o aumento do número de simulações. Começamos por realizar este estudo tendo em vista o parâmetro $a_{xm} =0.6$. O pacote **simglm** permite gerar aleatoriamente dados com base nas especificações pré-definidas do modelo. Assim, usando a função **simglm::replicate_simulation**, para fins de exercício académico, ajustamos o modelo de regressão apenas a 500 amostras.
```{r}
set.seed(1234) 
sim_arguments_1 <- list(
  formula =  m ~ 1 + x,
  fixed = list(x = list(var_type = 'continuous', mean = 0, sd = 1)),
  error = list(variance = sqrt(1-a^2)),
  sample_size = 200,
  reg_weights = c(0,a),
  model_fit = list(formula = m ~ 1 + x,
                   model_function = 'lm'),
  reg_weights_model = c(0,a),
  replications = 500,
  extract_coefficients = TRUE
)

dfsim_m_rep <- replicate_simulation(sim_arguments_1) 
head(dfsim_m_rep)
```

Criamos a função **simcoef** para extrair o parâmetro alvo ($a_{xm}$) e calcular a sua distribuição.
```{r}
simcoef <- function(listsim,
                    parameter = "x",
                    value = "estimate") {
  list_coef <- lapply(listsim, as.data.frame)
  coefs <- as.numeric()
  for (i in 1:length(list_coef)) {
    coefs[i] <- list_coef[[i]][list_coef[[i]]$term == parameter, value]
  }
  return(coefs)
}

mean(simcoef(dfsim_m_rep))
ggplot(data.frame(a=simcoef(dfsim_m_rep)), aes(x=a)) + geom_histogram() + labs(title="histograma parametro a")
```

Repetimos o procedimento anterior para as estimativas de *y* dado *x* e *m*, também para $n=500$.
```{r}
set.seed(321) 

sim_arguments_2 <- list(
  formula =  y ~ 1 + x + m,
  fixed = list(x = list(var_type = 'continuous', mean = 0, sd = 1),
               m = list(var_type = 'continuous', mean = 0, sd = 1)),
  error = list(variance = 1-(cp^2 + b^2 + 2*a*cp*b)),
  sample_size = 200,
  reg_weights = c(0,cp, b),
  model_fit = list(formula = y ~ 1 + x + m,
                   model_function = 'lm'),
  reg_weights_model = c(0,cp, b),
  replications = 500,
  extract_coefficients = TRUE
)

dfsim_y_rep <- replicate_simulation(sim_arguments_2) 
head(dfsim_y_rep)
```


```{r}
mean(simcoef(dfsim_y_rep, parameter="x"))
ggplot(data.frame(cp=simcoef(dfsim_y_rep, parameter="x")), aes(x=cp)) + geom_histogram() + labs(title="histograma parametro cp")
mean(simcoef(dfsim_y_rep, parameter="m"))
ggplot(data.frame(b=simcoef(dfsim_y_rep, parameter="m")), aes(x=b)) + geom_histogram() + labs(title="histograma parametro b")
```

A função **simglm::compute_statistics** permite calcular a potencia e probabilidade de erro do tipo 1, neste caso quando se estima este modelo para amostras de $n=500$.

```{r, warning=FALSE}
compute_statistics(dfsim_m_rep, sim_arguments)
compute_statistics(dfsim_y_rep, sim_arguments)
```
Verificamos, como esperado, que os valores das estimativas pelo método Monte Carlo convergem para os valores da população quando o número de amostras aumenta.

***


# Parte 3: Teste de hipótese sobre o efeito indireto em mediação

ANA & ANA


Apresentação das diferentes abordagens para teste da significância dos efeitos indiretos: vantagens e desvantagens.












***

# Parte 4: Análise comparativa dos teste de hipótese sobre o efeito indiretos

## Teste de Sobel
Como discutido na secção anterior do presente relatório, o teste de Sobel é uma abordagem paramétrica à significância estatística do parâmetro de efeitos indiretos no contexto do modelo de mediação. Trata-se de um teste que tem por base uma distribuição z calculada através da seguinte equação:

\begin{equation}
\tag{8}
z = \frac{a_{xm}b_{my|x}}{SE}  
\end{equation}

No teste Sobel o desvio médio da estimativa do efeito indireto é dado pela seguinte equação:

\begin{equation}
\tag{9}
SE=\sqrt{(a^2_{xm}s^2_{b_{my|x}}+b^2_{my|x}s^2_{a_{xm}})}
\end{equation}

Nesta equação $s^2$ representa a variância dos parâmetros $a_{xm}$ e $b_{my|x}$. As seguintes linhas de código implementa o teste de Sobel no R. Para exemplificar utilizaremos a base de dados **df1** ($n=100$) gerada na parte 2 do presente relatório.

**Passo 1:** Ajustamento dos modelos e extração dos coeficientes $a_{xm}$ e $b_{my|x}$
```{r}
model1 <- lm(formula = m ~ x, data=df1)
summary(model1)
a <- model1$coefficient[2]

model2 <- lm(formula = y ~ x + m, data=df1)
summary(model2)
b <- model2$coefficient[3]
```

**Passo 2:** Extração dos desvio padrão (SE) das estimativas
```{r}
SEa <- coef(summary(model1))[2, 2]
SEb <- coef(summary(model2))[3, 2]
```

**Passo 3:** Cálculo do desvio padrão do efeito indireto e estatística do teste com recurso às equações 8 e 9.
```{r}
SE <- sqrt(a^2*SEb^2 + b^2*SEa^2)
z <- a*b/SE
```

**Passo 4:** Cálculo da probabilidade associada ao valor do teste calculado, tomando por referência uma distribuição z. Em alternativa, comparar o valor absoluto da estatística do teste com o valor crítico da distribuição z para um determinado alpha.
```{r}
p <- pnorm(-abs(z)) * 2
# and not p <- 1-pnorm(z) as in paper

alpha=.05
sig <- qnorm(1-alpha/2) < abs(z)
```

Criamos a função *sobeltest*, com base nos passos anteriores, para implementar automaticamente o teste de Sobel no R.

```{r}
sobeltest <- function(data, x, m, y, alpha=.05){
#Passo 1
model1 <- lm(formula = m ~ x, data=data)
summary(model1)
a <- model1$coefficient[2]

model2 <- lm(formula = y ~ x + m, data=data)
summary(model2)
b <- model2$coefficient[3]

# Passo 2
SEa <- coef(summary(model1))[2, 2]
SEb <- coef(summary(model2))[3, 2]

# Passo 3
SE <- sqrt(a^2*SEb^2 + b^2*SEa^2)
z <- a*b/SE

# Passo 4
p <- pnorm(-abs(z)) * 2
# and not p <- 1-pnorm(z) as in paper

sig <- qnorm(1-alpha/2) < abs(z)
return(list(teststat=z, pvalue=p, sig=sig))
}

test <- sobeltest(x, m, y, data=df1)
```

### Limitações do teste de Sobel
Como discutido anteriormente (ver secção 3 do presente relatório), o teste de Sobel assume o pressuposto de que o produto de duas variáveis aleatórias normais apresenta uma distribuição também normal. No entanto, este pressuposto é frequentemente violado na prática. Por conseguinte, a multiplicação dos coeficientes de regressão $a_{xm}$ e $b_{my|x}$ apresenta frequentemente uma distribuição que se afasta da distribuição normal, caracterizada normalmente por elevada assimetria e curtose. O seguinte histograma representa a distribuição de duas variáveis (x e y) aleatórias (n=30) com distribuição normal. 
```{r}
ggplot(data.frame(xy=rnorm(30)*rnorm(30)), aes(x=xy)) + geom_histogram() + labs(title="histograma parametro x*y")
```

## Estimação da significância de efeitos indiretos através do método de bootstrap

Neste projeto implementamos dois tipos de bootstrap, o bootstrap percentílico (Percentile Bootstrap Method) e o bootstrap com correção de viés e fator de aceleração (Bias corrected e accelarated bootstrap).

Para implementar estes dois métodos bootstrap foi necessário criar uma função geradora das estimativas para o coeficiente *ab*. Usamos cálculo matricial para encontrar o parâmetro ab, aplicando a seguinte equação para estimação dos parâmetros de um modelo de regressão linear múltipla:

\begin{equation}
\tag{10}
\hat{\beta}=(\textbf{X}^T\textbf{X})^{-1}\textbf{X}^Ty
\end{equation}

```{r}
names(df1)
d <- as.matrix(cbind(int=rep(1, length(df1$x)), x=df1$x, m=df1$m, y=df1$y))
b <- solve(t(d[,1:3])%*%d[,1:3])%*%t(d[,1:3])%*%d[,4]
a <- solve(t(d[,1:2])%*%d[,1:2])%*%t(d[,1:2])%*%d[,3]
ab <- a[2,1]*b[3,1]
```

Com base na equação 10, criamos a função *stat_function*, que será utilizada no contexto do bootstrap para estimar os efeitos indiretos **ab**.
```{r}
head(df1)
stat_function <- function(df){
  d <- as.matrix(cbind(int=rep(1, dim(df)[1]), x=df[,"x"], m=df[,"m"], y=df[,"y"]))
  b <- solve(t(d[,1:3])%*%d[,1:3])%*%t(d[,1:3])%*%d[,4]
  a <- solve(t(d[,1:2])%*%d[,1:2])%*%t(d[,1:2])%*%d[,3]
  ab <- a[2,1]*b[3,1] 
  return(ab)
}
stat_function(df1)
```


### Bootstrap percentílico (Percentile Bootstrap Method)

A implementação do bootstrap percentílico no R é bastante direta. Trata-se da abordagem bootstrap mais simples, permitindo calcular intervalos de confiança entre $100*(\frac{\alpha}{2})$ e $100*(1-\frac{\alpha}{2})$ da distribuição bootstrap gerada do parâmetro $\theta$. Esta distribuição obtém-se por método de re-amostragem com reposição, sendo que $\theta$ representa o parâmetro de interesse e $\alpha$ o nível de significância (Efron, 1982). Criamos a função *boot_perc* para implementar o bootstrap percentílico no R.

```{r}
boot_perc <- function(data, R=5000, alpha = .05) {
  data <- as.matrix(data)
  est <- stat_function(data)
  n <- dim(data)[1]
  N <- 1:n
  res <- rep(NA, R)
  for (i in 1:R) {
    #Select a bootstrap sample
    id <- sample(n, replace = TRUE)
    #Estimate index
    res[i] <- stat_function(data[id, ])
  }
  limits <- quantile(res, c(alpha / 2, 1 - alpha / 2))
  CI <- c(limits[[1]], limits[[2]])
  sig <- 0 < prod(sign(CI)) # serve para ver se o intervalo de confiânça contem ou não zero
  return(list(
    estimate = est,
    bootdist=res,
    BootConfInt = limits,
    sig = sig
  ))
}
```

O seguinte histograma representa a distribuição bootstrap com base nos dados da df1. Notar que esta base de dados foi gerar para resultar nos seguintes parâmetros:
$a_{xm} = 0.6$  
$b_{my|x} = 0.4$  
$c_{xy} = 0.3$  
$a_{xm}b_{my|x} = 0.24$  
```{r, warning=FALSE}
testboot1 <- boot_perc(df1)
ggplot(data.frame(theta=testboot1[[2]]), aes(x=theta)) + 
  geom_histogram() + 
  labs(title="Distribuição bootstrap para parametro ab e IC") + 
  geom_vline(xintercept=testboot1[[1]], color = "darkblue", size=1.5) + 
  geom_vline(xintercept=testboot1[[3]][1], color = "orange", size=.8, linetype="dashed") +
  geom_vline(xintercept=testboot1[[3]][2], color = "orange", size=.8, linetype="dashed") 

```

### Bootstrap com correção de viés e fator de aceleração (Bias corrected e accelarated bootstrap)

Duas limitações tê sido apontadas ao bootstrap percentílico. Primeiro, o bootstrap percentílico não tem em conta os dados originais resultado exclusivamente da re-amostragem com reposição. Segundo, o bootstrap percentílico não ajusta eventual assimetria da distribuição bootstrap. Para abordar estas limitações é proposto o método bootstrap com correção de viés e fator de aceleração (BCa) (Efron and Tibshirani, 1993). O BCa tem a consideração e ajusta a correção o viés que pode decorrer de uma eventual assimetria de distribuição bootstrap. A presença de assimetria em distribuições bootstrap é habitual. Neste sentido, o BCa foi desenvolvido para obter os intervalos de confiança com uma correção da assimetria (Efron and Tibshirani, 1993). Para o desenvolvimento deste método é necessário calcular uma constante de aceleração, denotada por $a$, que é estimada pelo método Jackknife. O intervalo bootstrap para o parametro $\theta$ tem a forma:

\begin{equation}
\tag{11}
g(u)=\hat{F}^{-1}(\Theta(\textit{Z}_0 + \frac{\textit{Z}_u + \textit{Z}_0}{1-a(\textit{Z}_0+ \textit{Z}_u)}))
\end{equation}

$\Theta(z)$, representa a função de distribuição da normal estandardizada  
$\textit{Z}_0$ = $\Theta^{-1}(\hat{F}(\hat{\theta}))$
$\textit{Z}_u$ = $\Theta^{-1}(u)$
*a* é a constante de aceleração

A constante de aceleração *a* assume a seguinte forma: 
\begin{equation}
\tag{12}
\hat{a}= \frac{1}{6} \frac{\sum_{i=1}^{n}I_{i}^{3}}{(\sum_{i=1}^{n}I_{i}^{2})^\frac{3}{2}}
\end{equation}

$I_i$ exprime a influência de $x_i$ na estimativa de $\theta$ sendo aproximada pelo método jackknife (Efron, 1987).

\begin{equation}
\tag{13}
I_i= (n-1) [\hat{\theta} - \hat{\theta}_i]
\end{equation}

Implementamos esta abordagem no R, criando a função **boot_cba**.
```{r}
boot_bca <- function(data, R=5000, alpha = .05) {
  data <- as.matrix(data)
  n <- dim(data)[1]
  est <- stat_function(data) # cálculo do parâmetro amostral
  # o primero loop faz o bootstrap
  res <- rep(NA, R)
  for (i in 1:R) {
    #Select a bootstrap sample
    id <- sample(n, replace = TRUE)
    #Estimate index
    res[i] <- stat_function(data[id,])
  }
  #Calcular as constantes
  z0 <- qnorm(mean(res <= rep(est, R)))
  zc <- qnorm(c(alpha / 2, 1 - alpha / 2)) # Quantis pretendidos
  
  # este segundo faz o jackknife para estimar o parâmetro a (aceleração)
  I <- rep(NA, n)
  for (i in 1:n) {
    #Remove ith data point
    datanew <- data[-i, ]
    #Estimate theta - distribuição jackkife para todos os possíveis n-1
    theta_jack <- stat_function(datanew)
    I[i] <- (n - 1) * (est - theta_jack)
  }
  
  #calculo da constante de aceleração
  a <- 1 / 6 * (sum(I ^ 3) / sum(I ^ 2) ^ 1.5)
  
  # Calculo dos quantis ajustados
  adj.alpha <- pnorm(z0 + (z0 + zc) / (1 - a * (z0 + zc)))
  limits <- quantile(res, adj.alpha)
  CI <- c(limits[[1]], limits[[2]])
  sig <- 0 < prod(sign(CI)) # serve para ver se o intervalo de confiança contem ou não zero
  return(list(
    estimate = est,
    bootdist = res,
    BootConfInt = limits,
    sig = sig
  ))
}
```

```{r}
testboot2 <- boot_bca(df1, R=5000)
lapply(testboot2, head)
```

O seguinte histograma representa a distribuição bootstrap com base nos dados da df1, e os intervalos de confiança calculados através do bootstrap percentílico e bootstrap com correção de viés e fator de aceleração. Mais uma vez notar que esta base de dados foi gerar para resultar nos seguintes parâmetros:
$a_{xm} = 0.6$  
$b_{my|x} = 0.4$  
$c_{xy} = 0.3$  
$a_{xm}b_{my|x} = 0.24$  

```{r}
ggplot(data.frame(theta=testboot1[[2]]), aes(x=theta)) + 
  geom_histogram() + 
  labs(title="Distribuição bootstrap para parametro ab e IC") + 
  geom_vline(xintercept=testboot1[[1]], color = "darkblue", size=1.5) + 
  geom_vline(xintercept=testboot1[[3]][1], color = "orange", size=.8, linetype="dashed") +
  geom_vline(xintercept=testboot1[[3]][2], color = "orange", size=.8, linetype="dashed") + 
  geom_vline(xintercept=testboot2[[3]][1], color = "darkgreen", size=1.3, linetype="dashed") +
  geom_vline(xintercept=testboot2[[3]][2], color = "darkgreen", size=1.3, linetype="dashed") 

```

## Análise da potências dos testes
Finalmente, analisamos a potência das três abordagens para cálculo da significância de efeitos indiretos no contexto de um modelo de mediação, nomeadamente teste de Sobel, bootstrap percentílico e bootstrap com correção de viés e fator de aceleração. 

A análise do poder permite, neste contexto verificar a probabilidade do teste encontrar um efeito significativo quando a hipótese nula é falsa, isto é quando existe efetivamente um efeito indireto diferente de zero. Para realizar esta análise da potência do teste simulamos várias experiências de em que o efeito indireto ab era conhecido e diferente de zero. Verificamos depois, para um certo número de replicações (para fins académicos n=100, embora na prática este número deverá ser bastante mais elevado), a frequência com que o teste detetou um efeito significativo para um $\alpha=.05$. Para conduzir esta análise do poder utilizamos as funções anteriormente criadas para estimar o teste de Sobel, bootstrap percentílico e bootstrap com correção de viés e fator de aceleração.
```{r}
(testboot1 <- sobeltest(x=x, m=m, y=y, data=df1))
testboot2 <- boot_perc(df1, R=5000)
lapply(testboot2, head)
testboot3 <- boot_bca(df1, R=5000)
lapply(testboot3, head)
```

A sintaxe para cálculo do poder foi adaptada de Caron & Valois (2018).

```{r}

PowerMediation <- function(MediationTest, a = .25, b = .6, c = .0, n = 40, R =
                             100, alpha = 0.05){
  # Warning : This function can be excessively slow with high replication values and high sample sizes,
  # especially with bootstrap
  # MediationTest = SobelTest.R or BaronKenny.R or BootTest.R or any function returning an output labelled sig indicating if the result is significant (TRUE or FALSE)
  TestSIG <- rep(NA, R)
  for(j in 1:R){
    data <- GenerateMediationData(n=n, a=a, b=b, c=c)
    RES <- MediationTest(data=data, alpha=alpha)
    TestSIG[j] <- RES$sig
  }
  Power <- round(sum(TestSIG)/R,3)
  return(list(Results=TestSIG, Power=Power))
}

```

A análise do poder foram feitas sobre amostras com as seguintes dimensões:  
n = {20, 30, 40, 50, 60, 70, 80, 90, 100, 150}

Os cenários para a análise do poder foram os seguinte: 
> Cenário 1: 

$a_{xm} = 0.335$  
$b_{my|x} = 0.300$  
$c_{xy} = 0.150$  
$a_{xm}b_{my|x} = 0.101$  

> Cenário 2: 

$a_{xm} = 0.500$  
$b_{my|x} = 0.400$  
$c_{xy} = 0.250$  
$a_{xm}b_{my|x} = 0.200$ 

> Cenário 3: 

$a_{xm} = 0.600$  
$b_{my|x} = 0.500$  
$c_{xy} = 0.350$  
$a_{xm}b_{my|x} = 0.300$ 

Os resultados desta análise da potência do teste são apresentados nos seguinte gráfico, o primeiro com a potência observada nas diferentes condições e o segundo com uma suavização da reta.
```{r}
load(file="power.Rdata")


ggplot(power_df, aes(x=n, y=power, color=test)) + 
  geom_point() +
  geom_line() + 
  facet_grid(cols = vars(condition)) + 
  ggtitle("Potencia dos testes para diferentes n tamanho do efeito indireto ") + 
  geom_hline(yintercept=.8, linetype="dashed", 
             color = "darkgrey", size=.8)


ggplot(power_df) + 
  geom_point(aes(x=n, y=power, color=test), size=1)+
  geom_smooth(ymax=1,aes(x=n, y=power, color=test), method = "glm", formula = y ~ poly(x, 2), se = FALSE) + 
  facet_grid(cols = vars(condition)) +  
  ggtitle("Potencia dos testes para diferentes n tamanho do efeito indireto \n (linha suavizada)") + 
  geom_hline(yintercept=.8, linetype="dashed", 
             color = "darkgrey", size=.8)
```

# Fontes bibliográficas  

- Baron, R. M., & Kenny, D. A. (1986). The moderator-mediator variable distinction in social psychological research: conceptual, strategic, and statistical considerations. *Journal of personality and social psychology*, 51(6), 1173–1182. https://doi.org/10.1037//0022-3514.51.6.1173

- Bollen, K. A., & Stine, R. (1990). Direct and Indirect Effects: Classical and Bootstrap Estimates of Variability. *Sociological Methodology, 20*, 115–140. https://doi.org/10.2307/271084

- Caron, Pier-Olivier, & Valois, Philippe (2018). A computational description of simple mediation analysis. *The Quantitative Methods for Psychology, 14* (2), 147-158. https://doi.org/10.20982/tqmp.14.2.p147  

- Efron, B. (1982). *The Jackknife, the bootstrap, and other resampling plans*. in CBMS-NSF Regional Conference Series in Applied Mathematics, Monograph 38 (Philadelphia, PA: SIAM). doi: 10.1137/1.9781611970319  

- Efron, B., & Tibshirani, R. J. (1993). *An Introduction to the Bootstrap*. New York, NY: Chapman and Hall. doi: 10.1007/978-1-4899-4541-9  

- Efron, B. (1987) Better Bootstrap Confidence Intervals. *Journal of the American Statistical Association*, 82:397, 171-185, DOI: 10.1080/01621459.1987.10478410

- MacKinnon, D. P., Cheong, J., Pirlott, A. G. (2012) In Cooper, H., Camic, P. M., Long, D. L., Panter, A. T., Rindskopf, D., Sher, K. J. (Eds.) (2012). *APA handbook of research methods in psychology*, Vol 2: Research designs: Quantitative, qualitative, neuropsychological, and biological., (pp. 313-331). Washington, DC, US: American Psychological Association.

- Jose, P. E. (2013). *Doing statistical mediation and moderation*. Guilford Press.